{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (28, 28)\n",
    "n_classes = 10\n",
    "\n",
    "imgs_train = mnist.train.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_val = mnist.validation.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_test = mnist.test.images.reshape((-1, 1, *img_size)) / 255\n",
    "\n",
    "y_train = mnist.train.labels.astype(np.int32)\n",
    "y_val = mnist.validation.labels.astype(np.int32)\n",
    "y_test = mnist.test.labels.astype(np.int32)\n",
    "\n",
    "def make_batch_iter(x, y, batch_size, shuffle=False):\n",
    "    n = len(x)\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        yield np.array(x_batch, np.float32), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cba(t, n_chans, kernel_size, name, training,\n",
    "        activation=tf.identity):\n",
    "    with tf.variable_scope(name):\n",
    "        t = tf.layers.conv2d(\n",
    "            t, n_chans, kernel_size, use_bias=False, \n",
    "            data_format='channels_first')\n",
    "        #t = tf.layers.batch_normalization(t, axis=1, training=training, fused=True)\n",
    "        t = slim.batch_norm(\n",
    "            t, decay=0.9, scale=True, is_training=training,\n",
    "            data_format='NCHW', fused=True)\n",
    "        return activation(t)\n",
    "\n",
    "def dba(t, units, name, training, activation=tf.identity):\n",
    "    with tf.variable_scope(name):\n",
    "        t = tf.layers.dropout(t, training=training)\n",
    "        t = tf.layers.dense(t, units, use_bias=False)\n",
    "        #t = tf.layers.batch_normalization(t, axis=1, training=training)\n",
    "        t = slim.batch_norm(\n",
    "            t, decay=0.9, scale=True, is_training=training, fused=True)\n",
    "        return activation(t)\n",
    "    \n",
    "\n",
    "def build_cnn(t, blocks, kernel_size, training, name):\n",
    "    with tf.variable_scope(name):\n",
    "        for i, n_chans in enumerate(blocks):\n",
    "            t = cba(t, n_chans, kernel_size, activation=tf.nn.relu,\n",
    "                    name='cba_{}'.format(i), training=training)\n",
    "            t = tf.layers.max_pooling2d(t, 2, 2, data_format='channels_first')\n",
    "        t = tf.reduce_mean(t, axis=(2, 3), name='global_average_pooling')\n",
    "    return t\n",
    "\n",
    "\n",
    "def build_mlp(t, blocks, training, name):\n",
    "    with tf.variable_scope(name):\n",
    "        for i, units in enumerate(blocks[:-1]):\n",
    "            t = dba(t, units, activation=tf.nn.relu,\n",
    "                    name='fc_{}'.format(i), training=training)\n",
    "        \n",
    "        t = dba(t, blocks[-1], name='logits', training=training)\n",
    "    return t\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, cnn_blocks, mpl_blocks, kernel_size):\n",
    "        self.x_ph = tf.placeholder(tf.float32, (None, 1, None, None))\n",
    "        self.training = tf.placeholder(tf.bool)\n",
    "        self.y_ph = tf.placeholder(tf.int64, (None,))\n",
    "\n",
    "        with tf.variable_scope('model'):\n",
    "            self.cnn = build_cnn(self.x_ph, cnn_blocks, kernel_size,\n",
    "                                 self.training, 'cnn')\n",
    "            self.logits = build_mlp(self.cnn, mlp_blocks,\n",
    "                                    self.training, 'mlp')\n",
    "        \n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(self.y_ph, self.logits)\n",
    "        self.acc = tf.contrib.metrics.accuracy(tf.argmax(self.logits, 1), self.y_ph)\n",
    "        \n",
    "        with tf.name_scope('summary'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('acc', self.acc)\n",
    "            self.summary = tf.summary.merge_all()\n",
    "        \n",
    "        self.train_op = slim.learning.create_train_op(self.loss, tf.train.AdamOptimizer())\n",
    "\n",
    "cnn_blocks = [32, 32, 64]\n",
    "mlp_blocks = [1024, 1024]\n",
    "kernel_size = 3\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "model = Model(cnn_blocks, mlp_blocks, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 500\n",
    "batch_size = 1024\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "file_writer = tf.summary.FileWriter('./log/new2', graph=graph, flush_secs=10)\n",
    "\n",
    "k = 0\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epoch):\n",
    "        train_iter = make_batch_iter(imgs_train, y_train, batch_size=batch_size)\n",
    "        val_iter = make_batch_iter(imgs_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in train_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: True}\n",
    "            _, loss, acc, summary = session.run([model.train_op, model.loss, model.acc, model.summary], feed_dict)\n",
    "            file_writer.add_summary(summary, k)\n",
    "            k += 1\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        train_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        train_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in val_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: False}\n",
    "            loss, acc = session.run([model.loss, model.acc], feed_dict)\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        val_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        val_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('Train:', train_loss, train_acc)\n",
    "        print('Val  :', val_loss, val_acc)\n",
    "        print('Time :', end - start)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
